{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\ajisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\ajisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ajisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\ajisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (3.11.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ajisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ajisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ajisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ajisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (2025.1.31)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ajisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (2.4.8)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ajisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ajisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ajisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ajisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\ajisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\ajisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.18.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\ajisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\n\u001b[32m      3\u001b[39m openai.api_key = \u001b[33m\"\u001b[39m\u001b[33msk-proj-DQ6Mn2Uz-CVgbV5S_wM7A-HTc4UsPQtsJeeijxu9rGfzqdqdsIvWJAHEtf_e7RCRxIW6GkXiWuT3BlbkFJ5d-919W4wDiUhc_IUPqCoiMt9AOs3IwX0Hpt9YNJoTq2TeZO3Vi4VeM2-iPikdP1LgZCpzKxYA\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m response = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-3.5-turbo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou are a helpful assistant.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m              \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHello! How are you?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(response[\u001b[33m\"\u001b[39m\u001b[33mchoices\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[39m, in \u001b[36mChatCompletion.create\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     27\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time.time() > start + timeout:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[39m, in \u001b[36mEngineAPIResource.create\u001b[39m\u001b[34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    129\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    136\u001b[39m     **params,\n\u001b[32m    137\u001b[39m ):\n\u001b[32m    138\u001b[39m     (\n\u001b[32m    139\u001b[39m         deployment_id,\n\u001b[32m    140\u001b[39m         engine,\n\u001b[32m   (...)\u001b[39m\u001b[32m    150\u001b[39m         api_key, api_base, api_type, api_version, organization, **params\n\u001b[32m    151\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     response, _, api_key = \u001b[43mrequestor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[32m    164\u001b[39m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[32m    165\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:298\u001b[39m, in \u001b[36mAPIRequestor.request\u001b[39m\u001b[34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m    278\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    279\u001b[39m     method,\n\u001b[32m   (...)\u001b[39m\u001b[32m    286\u001b[39m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    287\u001b[39m ) -> Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    288\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.request_raw(\n\u001b[32m    289\u001b[39m         method.lower(),\n\u001b[32m    290\u001b[39m         url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    296\u001b[39m         request_timeout=request_timeout,\n\u001b[32m    297\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m     resp, got_stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    299\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m.api_key\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:700\u001b[39m, in \u001b[36mAPIRequestor._interpret_response\u001b[39m\u001b[34m(self, result, stream)\u001b[39m\n\u001b[32m    692\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    693\u001b[39m         \u001b[38;5;28mself\u001b[39m._interpret_response_line(\n\u001b[32m    694\u001b[39m             line, result.status_code, result.headers, stream=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    695\u001b[39m         )\n\u001b[32m    696\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result.iter_lines())\n\u001b[32m    697\u001b[39m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    706\u001b[39m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    707\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:765\u001b[39m, in \u001b[36mAPIRequestor._interpret_response_line\u001b[39m\u001b[34m(self, rbody, rcode, rheaders, stream)\u001b[39m\n\u001b[32m    763\u001b[39m stream_error = stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp.data\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[32m200\u001b[39m <= rcode < \u001b[32m300\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handle_error_response(\n\u001b[32m    766\u001b[39m         rbody, rcode, resp.data, rheaders, stream_error=stream_error\n\u001b[32m    767\u001b[39m     )\n\u001b[32m    768\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[31mRateLimitError\u001b[39m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors."
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "              {\"role\": \"user\", \"content\": \"Hello! How are you?\"}]\n",
    ")\n",
    "\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'OpenAI'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mOpenAI\u001b[39;00m\n\u001b[32m      3\u001b[39m client = OpenAI(\n\u001b[32m      4\u001b[39m   api_key=\u001b[33m\"\u001b[39m\u001b[33msk-proj-wdWJeI-5k3YtfLDyV31kbVv-YEvS6OM2SSh8J5NPgom0uls75wTa4-0iXFz1E9jpnWLCNY5vOcT3BlbkFJOiIBiGRNomz4VapyKcOeR1aEQ3gqPpic2ynIMHpjD4NtbrNXS42VhhS1VqH2zmN1w3S7drg_IA\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m )\n\u001b[32m      7\u001b[39m completion = client.chat.completions.create(\n\u001b[32m      8\u001b[39m   model=\u001b[33m\"\u001b[39m\u001b[33mgpt-3.5-turbo\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m   messages=[\n\u001b[32m     10\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mwrite a haiku about ai\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m     11\u001b[39m   ]\n\u001b[32m     12\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'OpenAI'"
     ]
    }
   ],
   "source": [
    "import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"write a haiku about ai\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m  \u001b[38;5;66;03m# Correct import\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m client = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-3.5-turbo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWrite a haiku about AI\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(client[\u001b[33m\"\u001b[39m\u001b[33mchoices\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[39m, in \u001b[36mChatCompletion.create\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     27\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time.time() > start + timeout:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[39m, in \u001b[36mEngineAPIResource.create\u001b[39m\u001b[34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    129\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    136\u001b[39m     **params,\n\u001b[32m    137\u001b[39m ):\n\u001b[32m    138\u001b[39m     (\n\u001b[32m    139\u001b[39m         deployment_id,\n\u001b[32m    140\u001b[39m         engine,\n\u001b[32m   (...)\u001b[39m\u001b[32m    150\u001b[39m         api_key, api_base, api_type, api_version, organization, **params\n\u001b[32m    151\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     response, _, api_key = \u001b[43mrequestor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[32m    164\u001b[39m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[32m    165\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:298\u001b[39m, in \u001b[36mAPIRequestor.request\u001b[39m\u001b[34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m    278\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    279\u001b[39m     method,\n\u001b[32m   (...)\u001b[39m\u001b[32m    286\u001b[39m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    287\u001b[39m ) -> Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    288\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.request_raw(\n\u001b[32m    289\u001b[39m         method.lower(),\n\u001b[32m    290\u001b[39m         url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    296\u001b[39m         request_timeout=request_timeout,\n\u001b[32m    297\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m     resp, got_stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    299\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m.api_key\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:700\u001b[39m, in \u001b[36mAPIRequestor._interpret_response\u001b[39m\u001b[34m(self, result, stream)\u001b[39m\n\u001b[32m    692\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    693\u001b[39m         \u001b[38;5;28mself\u001b[39m._interpret_response_line(\n\u001b[32m    694\u001b[39m             line, result.status_code, result.headers, stream=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    695\u001b[39m         )\n\u001b[32m    696\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result.iter_lines())\n\u001b[32m    697\u001b[39m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    706\u001b[39m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    707\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:765\u001b[39m, in \u001b[36mAPIRequestor._interpret_response_line\u001b[39m\u001b[34m(self, rbody, rcode, rheaders, stream)\u001b[39m\n\u001b[32m    763\u001b[39m stream_error = stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp.data\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[32m200\u001b[39m <= rcode < \u001b[32m300\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handle_error_response(\n\u001b[32m    766\u001b[39m         rbody, rcode, resp.data, rheaders, stream_error=stream_error\n\u001b[32m    767\u001b[39m     )\n\u001b[32m    768\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[31mRateLimitError\u001b[39m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors."
     ]
    }
   ],
   "source": [
    "import openai  # Correct import\n",
    "\n",
    "client = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Write a haiku about AI\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(client[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.11.9' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"\n",
    "try:\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Hello\"}]\n",
    "    )\n",
    "    print(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "except openai.error.AuthenticationError:\n",
    "    print(\"âŒ API Key Invalid! Correct Key Use pannunga.\")\n",
    "except openai.error.RateLimitError:\n",
    "    print(\"ðŸš¨ API Rate Limit Exceeded! Try Later.\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Other Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for i in range(5):  # 5 Times Retry à®ªà®£à¯à®£à®²à®¾à®®à¯\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Hello\"}]\n",
    "        )\n",
    "        print(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "        break  # Success à®†à®©à®¾ Loop Stop à®†à®•à¯à®®à¯\n",
    "    except openai.error.RateLimitError:\n",
    "        print(\"ðŸš¨ API Rate Limit Exceeded! 5 seconds wait...\")\n",
    "        time.sleep(5)  # 5 Seconds à®•à®¾à®¤à¯à®¤à®¿à®°à¯, Try Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'openai' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     response = \u001b[43mopenai\u001b[49m.ChatCompletion.create(\n\u001b[32m      6\u001b[39m         model=\u001b[33m\"\u001b[39m\u001b[33mgpt-3.5-turbo\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m         messages=[{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mHello\u001b[39m\u001b[33m\"\u001b[39m}]\n\u001b[32m      8\u001b[39m     )\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(response[\u001b[33m\"\u001b[39m\u001b[33mchoices\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'openai' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(response[\u001b[33m\"\u001b[39m\u001b[33mchoices\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Success à®†à®©à®¾ Loop Stop à®†à®•à¯à®®à¯\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[43mopenai\u001b[49m.error.RateLimitError:\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸš¨ API Rate Limit Exceeded! 5 seconds wait...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m     time.sleep(\u001b[32m5\u001b[39m)  \u001b[38;5;66;03m# 5 Seconds à®•à®¾à®¤à¯à®¤à®¿à®°à¯, Try Again\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'openai' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for i in range(5):  # 5 Times Retry à®ªà®£à¯à®£à®²à®¾à®®à¯\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Hello\"}]\n",
    "        )\n",
    "        print(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "        break  # Success à®†à®©à®¾ Loop Stop à®†à®•à¯à®®à¯\n",
    "    except openai.error.RateLimitError:\n",
    "        print(\"ðŸš¨ API Rate Limit Exceeded! 5 seconds wait...\")\n",
    "        time.sleep(5)  # 5 Seconds à®•à®¾à®¤à¯à®¤à®¿à®°à¯, Try Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m  \u001b[38;5;66;03m# Missing à®‡à®°à¯à®¨à¯à®¤à®¾ Add à®ªà®£à¯à®£à¯à®™à¯à®•\u001b[39;00m\n\u001b[32m      3\u001b[39m api_key = \u001b[33m\"\u001b[39m\u001b[33msk-proj-wdWJeI-5k3YtfLDyV31kbVv-YEvS6OM2SSh8J5NPgom0uls75wTa4-0iXFz1E9jpnWLCNY5vOcT3BlbkFJOiIBiGRNomz4VapyKcOeR1aEQ3gqPpic2ynIMHpjD4NtbrNXS42VhhS1VqH2zmN1w3S7drg_IA\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Replace with your OpenAI API Key\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m response = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-3.5-turbo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHello!\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(response[\u001b[33m\"\u001b[39m\u001b[33mchoices\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[39m, in \u001b[36mChatCompletion.create\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     27\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time.time() > start + timeout:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[39m, in \u001b[36mEngineAPIResource.create\u001b[39m\u001b[34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    129\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    136\u001b[39m     **params,\n\u001b[32m    137\u001b[39m ):\n\u001b[32m    138\u001b[39m     (\n\u001b[32m    139\u001b[39m         deployment_id,\n\u001b[32m    140\u001b[39m         engine,\n\u001b[32m   (...)\u001b[39m\u001b[32m    150\u001b[39m         api_key, api_base, api_type, api_version, organization, **params\n\u001b[32m    151\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     response, _, api_key = \u001b[43mrequestor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[32m    164\u001b[39m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[32m    165\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:298\u001b[39m, in \u001b[36mAPIRequestor.request\u001b[39m\u001b[34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m    278\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    279\u001b[39m     method,\n\u001b[32m   (...)\u001b[39m\u001b[32m    286\u001b[39m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    287\u001b[39m ) -> Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    288\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.request_raw(\n\u001b[32m    289\u001b[39m         method.lower(),\n\u001b[32m    290\u001b[39m         url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    296\u001b[39m         request_timeout=request_timeout,\n\u001b[32m    297\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m     resp, got_stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    299\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m.api_key\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:700\u001b[39m, in \u001b[36mAPIRequestor._interpret_response\u001b[39m\u001b[34m(self, result, stream)\u001b[39m\n\u001b[32m    692\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    693\u001b[39m         \u001b[38;5;28mself\u001b[39m._interpret_response_line(\n\u001b[32m    694\u001b[39m             line, result.status_code, result.headers, stream=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    695\u001b[39m         )\n\u001b[32m    696\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result.iter_lines())\n\u001b[32m    697\u001b[39m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    706\u001b[39m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    707\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:765\u001b[39m, in \u001b[36mAPIRequestor._interpret_response_line\u001b[39m\u001b[34m(self, rbody, rcode, rheaders, stream)\u001b[39m\n\u001b[32m    763\u001b[39m stream_error = stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp.data\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[32m200\u001b[39m <= rcode < \u001b[32m300\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handle_error_response(\n\u001b[32m    766\u001b[39m         rbody, rcode, resp.data, rheaders, stream_error=stream_error\n\u001b[32m    767\u001b[39m     )\n\u001b[32m    768\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[31mRateLimitError\u001b[39m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors."
     ]
    }
   ],
   "source": [
    "import openai  # Missing à®‡à®°à¯à®¨à¯à®¤à®¾ Add à®ªà®£à¯à®£à¯à®™à¯à®•\n",
    "\n",
    "api_key = \"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello!\"}]\n",
    ")\n",
    "\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFound",
     "evalue": "404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFound\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m model = genai.GenerativeModel(\u001b[33m\"\u001b[39m\u001b[33mgemini-pro\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Query\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m response = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWrite a haiku about AI\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Output\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\generativeai\\generative_models.py:331\u001b[39m, in \u001b[36mGenerativeModel.generate_content\u001b[39m\u001b[34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[39m\n\u001b[32m    329\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_iterator(iterator)\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_response(response)\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.InvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:835\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    834\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m835\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    289\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    290\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    291\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    292\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    150\u001b[39m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    152\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[32m    164\u001b[39m     time.sleep(sleep)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[32m    207\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    208\u001b[39m         error_list,\n\u001b[32m    209\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    210\u001b[39m         original_timeout,\n\u001b[32m    211\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    214\u001b[39m     on_error_fn(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    146\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(*args, **kwargs)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mNotFound\u001b[39m: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods."
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# API Key Setup\n",
    "genai.configure(api_key=\"\n",
    "\n",
    "# Model Setup\n",
    "model = genai.GenerativeModel(\"gemini-pro\")\n",
    "\n",
    "# Query\n",
    "response = model.generate_content(\"Write a haiku about AI\")\n",
    "\n",
    "# Output\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-1.5-pro-experimental\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"\n",
    "\n",
    "models = genai.list_models()\n",
    "for model in models:\n",
    "    print(model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code blooms into thought,\n",
      "Learning whispers on the breeze,\n",
      "Future yet unknown. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# API Key Setup\n",
    "genai.configure(api_key=\")\n",
    "\n",
    "# Model Setup\n",
    "model = genai.GenerativeModel(\"gemini-1.5-pro\")  # Use the correct model name\n",
    "\n",
    "# Query\n",
    "response = model.generate_content(\"Write a haiku about AI\")\n",
    "\n",
    "# Output\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install speechrecognition google-generativeai pyttsx3 sounddevice numpy wavio googlesearch-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Options: 1. Talk to AI  2. Record Voice  3. Type & Speak  4. Generate Story  5. YouTube Search  6. Google Search  7. Exit\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import google.generativeai as genai\n",
    "import pyttsx3\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import wavio\n",
    "import webbrowser\n",
    "import googlesearch\n",
    "\n",
    "# Configure AI Key\n",
    "genai.configure(api_key=\"\")\n",
    "\n",
    "# Initialize Text-to-Speech\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "\n",
    "def speak(text):\n",
    "    \"\"\"Convert text to speech\"\"\"\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def listen():\n",
    "    \"\"\"Listen and convert speech to text\"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Speak now...\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "    \n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        print(f\"You: {text}\")\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Couldn't understand.\")\n",
    "        return None\n",
    "    except sr.RequestError:\n",
    "        print(\"Speech service down.\")\n",
    "        return None\n",
    "\n",
    "def chat_with_ai(user_input):\n",
    "    \"\"\"Chat with AI using Gemini\"\"\"\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
    "    response = model.generate_content(user_input)\n",
    "    return response.text\n",
    "\n",
    "def record_audio(filename=\"output.wav\", duration=5, samplerate=44100):\n",
    "    \"\"\"Record and save voice\"\"\"\n",
    "    print(\"Recording...\")\n",
    "    recording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=2, dtype=np.int16)\n",
    "    sd.wait()\n",
    "    wavio.write(filename, recording, samplerate)\n",
    "    print(f\"Audio saved as {filename}\")\n",
    "\n",
    "def google_search(query):\n",
    "    \"\"\"Search Google and return top result\"\"\"\n",
    "    search_results = list(googlesearch.search(query, num_results=1))\n",
    "    if search_results:\n",
    "        print(f\"Google Search Result: {search_results[0]}\")\n",
    "        webbrowser.open(search_results[0])\n",
    "        return search_results[0]\n",
    "    else:\n",
    "        return \"No results found.\"\n",
    "\n",
    "def youtube_search(query):\n",
    "    \"\"\"Search YouTube and open first video\"\"\"\n",
    "    search_url = f\"https://www.youtube.com/results?search_query={query.replace(' ', '+')}\"\n",
    "    print(f\"Opening YouTube search: {search_url}\")\n",
    "    webbrowser.open(search_url)\n",
    "    return search_url\n",
    "\n",
    "while True:\n",
    "    print(\"\\nOptions: 1. Talk to AI  2. Record Voice  3. Type & Speak  4. Generate Story  5. YouTube Search  6. Google Search  7. Exit\")\n",
    "    choice = input(\"Choose an option: \")\n",
    "    print(\"user chose\",choice)\n",
    "\n",
    "    if choice == \"1\":\n",
    "        user_text = listen()\n",
    "        if user_text:\n",
    "            response = chat_with_ai(user_text)\n",
    "            print(f\"Bot: {response}\")\n",
    "            speak(response)\n",
    "\n",
    "    elif choice == \"2\":\n",
    "        record_audio()\n",
    "\n",
    "    elif choice == \"3\":\n",
    "        text = input(\"Enter text: \")\n",
    "        speak(text)\n",
    "\n",
    "    elif choice == \"4\":\n",
    "        heading = input(\"Enter Story Heading: \")\n",
    "        story = chat_with_ai(f\"Write a short story about {heading}\")\n",
    "        print(f\"\\nStory:\\n{story}\")\n",
    "        speak(story)\n",
    "\n",
    "    elif choice == \"5\":\n",
    "        query = input(\"Enter YouTube Search: \")\n",
    "        youtube_search(query)\n",
    "\n",
    "    elif choice == \"6\":\n",
    "        query = input(\"Enter Google Search: \")\n",
    "        google_search(query)\n",
    "\n",
    "    elif choice == \"7\":\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid option. Try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://sloanreview.mit.edu/article/five-trends-in-ai-and-data-science-for-2025/\n",
      "https://www.techtarget.com/searchenterpriseai/tip/9-top-AI-and-machine-learning-trends\n",
      "https://news.microsoft.com/source/features/ai/6-ai-trends-youll-see-more-of-in-2025/\n",
      "https://in.element14.com/latest-trends-in-artificial-intelligence?srsltid=AfmBOoqcj1dsUWjUJL0fADczrOc9kYl2r_diVo87nPHLv9b8G5pWvK7P\n",
      "https://www.coursera.org/articles/ai-trends\n"
     ]
    }
   ],
   "source": [
    "from googlesearch import search  \n",
    "\n",
    "query = \"Latest AI Trends\"\n",
    "for result in search(query, num_results=5):\n",
    "    print(result)  # Google search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.geeksforgeeks.org/machine-learning/\n",
      "https://www.w3schools.com/python/python_ml_getting_started.asp\n",
      "https://github.com/ujjwalkarn/Machine-Learning-Tutorials\n"
     ]
    }
   ],
   "source": [
    "from googlesearch import search  \n",
    "\n",
    "query = \"Machine Learning tutorials\"\n",
    "for result in search(query, num_results=3, lang=\"en\"):  \n",
    "    print(result)  # Indian Google search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import webbrowser\n",
    "\n",
    "query = \"Machine Learning tutorials\"\n",
    "google_url = f\"https://www.google.com/search?q={query}\"\n",
    "webbrowser.open(google_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GEMINI_API_KEY\"] = \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Options: 1. Talk to AI  2. Record Voice  3. Type & Speak  4. Generate Story  5. YouTube Search  6. Google Search  7. Exit\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import google.generativeai as genai\n",
    "import pyttsx3\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import wavio\n",
    "import webbrowser\n",
    "import googlesearch\n",
    "\n",
    "# Configure AI Key\n",
    "genai.configure(api_key=)\n",
    "\n",
    "# Initialize Text-to-Speech\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "\n",
    "def speak(text):\n",
    "    \"\"\"Convert text to speech\"\"\"\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def listen():\n",
    "    \"\"\"Listen and convert speech to text\"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Speak now...\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "    \n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        print(f\"You: {text}\")\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Couldn't understand.\")\n",
    "        return None\n",
    "    except sr.RequestError:\n",
    "        print(\"Speech service down.\")\n",
    "        return None\n",
    "\n",
    "def chat_with_ai(user_input):\n",
    "    \"\"\"Chat with AI using Gemini\"\"\"\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
    "    response = model.generate_content(user_input)\n",
    "    return response.text\n",
    "\n",
    "def record_audio(filename=\"output.wav\", duration=5, samplerate=44100):\n",
    "    \"\"\"Record and save voice\"\"\"\n",
    "    print(\"Recording...\")\n",
    "    recording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=2, dtype=np.int16)\n",
    "    sd.wait()\n",
    "    wavio.write(filename, recording, samplerate)\n",
    "    print(f\"Audio saved as {filename}\")\n",
    "\n",
    "def google_search(query):\n",
    "    \"\"\"Search Google and return top result\"\"\"\n",
    "    search_results = list(googlesearch.search(query, num_results=1))\n",
    "    if search_results:\n",
    "        print(f\"Google Search Result: {search_results[0]}\")\n",
    "        webbrowser.open(search_results[0])\n",
    "        return search_results[0]\n",
    "    else:\n",
    "        return \"No results found.\"\n",
    "\n",
    "def youtube_search(query):\n",
    "    \"\"\"Search YouTube and open first video\"\"\"\n",
    "    search_url = f\"https://www.youtube.com/results?search_query={query.replace(' ', '+')}\"\n",
    "    print(f\"Opening YouTube search: {search_url}\")\n",
    "    webbrowser.open(search_url)\n",
    "    return search_url\n",
    "\n",
    "while True:\n",
    "    print(\"\\nOptions: 1. Talk to AI  2. Record Voice  3. Type & Speak  4. Generate Story  5. YouTube Search  6. Google Search  7. Exit\")\n",
    "    choice = input(\"Choose an option: \").strip()\n",
    "    if choice == \"1\":\n",
    "        user_text = listen()\n",
    "        if user_text:\n",
    "            response = chat_with_ai(user_text)\n",
    "            print(f\"Bot: {response}\")\n",
    "            speak(response)\n",
    "\n",
    "    elif choice == \"2\":\n",
    "        record_audio()\n",
    "\n",
    "    elif choice == \"3\":\n",
    "        text = input(\"Enter text: \")\n",
    "        speak(text)\n",
    "\n",
    "    elif choice == \"4\":\n",
    "        heading = input(\"Enter Story Heading: \")\n",
    "        story = chat_with_ai(f\"Write a short story about {heading}\")\n",
    "        print(f\"\\nStory:\\n{story}\")\n",
    "        speak(story)\n",
    "\n",
    "    elif choice == \"5\":\n",
    "        query = input(\"Enter YouTube Search: \")\n",
    "        youtube_search(query)\n",
    "\n",
    "    elif choice == \"6\":\n",
    "        query = input(\"Enter Google Search: \")\n",
    "        google_search(query)\n",
    "\n",
    "    elif choice == \"7\":\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid option. Try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No Default Input Device Available",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspeech_recognition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msr\u001b[39;00m\n\u001b[32m      2\u001b[39m recognizer = sr.Recognizer()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMicrophone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m source:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSay something...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m     audio = recognizer.listen(source)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\speech_recognition\\__init__.py:82\u001b[39m, in \u001b[36mMicrophone.__init__\u001b[39m\u001b[34m(self, device_index, sample_rate, chunk_size)\u001b[39m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[32m0\u001b[39m <= device_index < count, \u001b[33m\"\u001b[39m\u001b[33mDevice index out of range (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m devices available; device index should be between 0 and \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m inclusive)\u001b[39m\u001b[33m\"\u001b[39m.format(count, count - \u001b[32m1\u001b[39m)\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# automatically set the sample rate to the hardware's default sample rate if not specified\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     device_info = audio.get_device_info_by_index(device_index) \u001b[38;5;28;01mif\u001b[39;00m device_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43maudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_default_input_device_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device_info.get(\u001b[33m\"\u001b[39m\u001b[33mdefaultSampleRate\u001b[39m\u001b[33m\"\u001b[39m), (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m device_info[\u001b[33m\"\u001b[39m\u001b[33mdefaultSampleRate\u001b[39m\u001b[33m\"\u001b[39m] > \u001b[32m0\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mInvalid device info returned from PyAudio: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(device_info)\n\u001b[32m     84\u001b[39m     sample_rate = \u001b[38;5;28mint\u001b[39m(device_info[\u001b[33m\"\u001b[39m\u001b[33mdefaultSampleRate\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyaudio\\__init__.py:812\u001b[39m, in \u001b[36mPyAudio.get_default_input_device_info\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    803\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_default_input_device_info\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    804\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Returns the default input device parameters as a dictionary.\u001b[39;00m\n\u001b[32m    805\u001b[39m \n\u001b[32m    806\u001b[39m \u001b[33;03m    The keys of the dictionary mirror the data fields of PortAudio's\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    810\u001b[39m \u001b[33;03m    :rtype: dict\u001b[39;00m\n\u001b[32m    811\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m812\u001b[39m     device_index = \u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_default_input_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    813\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_device_info_by_index(device_index)\n",
      "\u001b[31mOSError\u001b[39m: No Default Input Device Available"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "recognizer = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Say something...\")\n",
    "    audio = recognizer.listen(source)\n",
    "print(\"Captured voice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSay something...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m audio = \u001b[43mrecognizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\speech_recognition\\__init__.py:460\u001b[39m, in \u001b[36mRecognizer.listen\u001b[39m\u001b[34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\speech_recognition\\__init__.py:466\u001b[39m, in \u001b[36mRecognizer._listen\u001b[39m\u001b[34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[39m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(source, AudioSource), \u001b[33m\"\u001b[39m\u001b[33mSource must be an audio source\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m source.stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mAudio source must be entered before listening, see documentation for ``AudioSource``; are you using ``source`` outside of a ``with`` statement?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pause_threshold >= \u001b[38;5;28mself\u001b[39m.non_speaking_duration >= \u001b[32m0\u001b[39m\n",
      "\u001b[31mAssertionError\u001b[39m: Audio source must be entered before listening, see documentation for ``AudioSource``; are you using ``source`` outside of a ``with`` statement?",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m recognizer = sr.Recognizer()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMicrophone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_index\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Mic index à®®à®¾à®±à¯à®±à¯\u001b[39;49;00m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSay something...\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecognizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\speech_recognition\\__init__.py:181\u001b[39m, in \u001b[36mMicrophone.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_value, traceback)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_value, traceback):\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclose\u001b[49m()\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    183\u001b[39m         \u001b[38;5;28mself\u001b[39m.stream = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'close'"
     ]
    }
   ],
   "source": [
    "recognizer = sr.Recognizer()\n",
    "with sr.Microphone(device_index=1) as source:  # Mic index à®®à®¾à®±à¯à®±à¯\n",
    "    print(\"Say something...\")\n",
    "    audio = recognizer.listen(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No Default Input Device Available",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspeech_recognition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msr\u001b[39;00m\n\u001b[32m      3\u001b[39m recognizer = sr.Recognizer()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMicrophone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m source:\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSay something...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m     audio = recognizer.listen(source)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\speech_recognition\\__init__.py:82\u001b[39m, in \u001b[36mMicrophone.__init__\u001b[39m\u001b[34m(self, device_index, sample_rate, chunk_size)\u001b[39m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[32m0\u001b[39m <= device_index < count, \u001b[33m\"\u001b[39m\u001b[33mDevice index out of range (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m devices available; device index should be between 0 and \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m inclusive)\u001b[39m\u001b[33m\"\u001b[39m.format(count, count - \u001b[32m1\u001b[39m)\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# automatically set the sample rate to the hardware's default sample rate if not specified\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     device_info = audio.get_device_info_by_index(device_index) \u001b[38;5;28;01mif\u001b[39;00m device_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43maudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_default_input_device_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device_info.get(\u001b[33m\"\u001b[39m\u001b[33mdefaultSampleRate\u001b[39m\u001b[33m\"\u001b[39m), (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m device_info[\u001b[33m\"\u001b[39m\u001b[33mdefaultSampleRate\u001b[39m\u001b[33m\"\u001b[39m] > \u001b[32m0\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mInvalid device info returned from PyAudio: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(device_info)\n\u001b[32m     84\u001b[39m     sample_rate = \u001b[38;5;28mint\u001b[39m(device_info[\u001b[33m\"\u001b[39m\u001b[33mdefaultSampleRate\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyaudio\\__init__.py:812\u001b[39m, in \u001b[36mPyAudio.get_default_input_device_info\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    803\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_default_input_device_info\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    804\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Returns the default input device parameters as a dictionary.\u001b[39;00m\n\u001b[32m    805\u001b[39m \n\u001b[32m    806\u001b[39m \u001b[33;03m    The keys of the dictionary mirror the data fields of PortAudio's\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    810\u001b[39m \u001b[33;03m    :rtype: dict\u001b[39;00m\n\u001b[32m    811\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m812\u001b[39m     device_index = \u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_default_input_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    813\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_device_info_by_index(device_index)\n",
      "\u001b[31mOSError\u001b[39m: No Default Input Device Available"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Say something...\")\n",
    "    audio = recognizer.listen(source)\n",
    "    print(\"Captured voice!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSay something...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m audio = \u001b[43mrecognizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCaptured voice\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\speech_recognition\\__init__.py:460\u001b[39m, in \u001b[36mRecognizer.listen\u001b[39m\u001b[34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\speech_recognition\\__init__.py:466\u001b[39m, in \u001b[36mRecognizer._listen\u001b[39m\u001b[34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[39m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(source, AudioSource), \u001b[33m\"\u001b[39m\u001b[33mSource must be an audio source\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m source.stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mAudio source must be entered before listening, see documentation for ``AudioSource``; are you using ``source`` outside of a ``with`` statement?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pause_threshold >= \u001b[38;5;28mself\u001b[39m.non_speaking_duration >= \u001b[32m0\u001b[39m\n",
      "\u001b[31mAssertionError\u001b[39m: Audio source must be entered before listening, see documentation for ``AudioSource``; are you using ``source`` outside of a ``with`` statement?",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m recognizer = sr.Recognizer()\n\u001b[32m      4\u001b[39m mic = sr.Microphone(device_index=\u001b[32m0\u001b[39m)  \u001b[38;5;66;03m# Change index if needed\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmic\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSay something...\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecognizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ajisha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\speech_recognition\\__init__.py:181\u001b[39m, in \u001b[36mMicrophone.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_value, traceback)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_value, traceback):\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclose\u001b[49m()\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    183\u001b[39m         \u001b[38;5;28mself\u001b[39m.stream = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'close'"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "mic = sr.Microphone(device_index=0)  # Change index if needed\n",
    "\n",
    "with mic as source:\n",
    "    print(\"Say something...\")\n",
    "    audio = recognizer.listen(source)\n",
    "    print(\"Captured voice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3584168525.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mwith sr.Microphone(device_index=1) as source:\u001b[39m\n                                                 ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "with sr.Microphone(device_index=1) as source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Microsoft Sound Mapper - Output', 'Headphones (High Definition Aud', 'Speakers (High Definition Audio', 'Primary Sound Driver', 'Headphones (High Definition Audio Device)', 'Speakers (High Definition Audio Device)', 'Speakers (High Definition Audio Device)', 'Headphones (High Definition Audio Device)', 'Headphones (HD Audio Headphone)', 'Speakers (HD Audio Speaker)']\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "print(sr.Microphone.list_microphone_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
